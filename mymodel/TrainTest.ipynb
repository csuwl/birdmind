{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-09T06:16:40.262914Z",
     "start_time": "2025-02-09T06:16:40.201609Z"
    }
   },
   "source": [
    "import torch\n",
    "\n",
    "from mymodel.Model import Model, ModelArgs\n",
    "\n",
    "with open(\"../sales_textbook.txt\", \"r\") as file:\n",
    "    text = file.read()\n",
    "    # print(text)\n",
    "\n",
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "tokens = tokenizer.encode(text)\n",
    "print(len(tokens))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77919\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T06:16:40.371742Z",
     "start_time": "2025-02-09T06:16:40.369091Z"
    }
   },
   "cell_type": "code",
   "source": "train_index =  int(len(tokens)*0.9)",
   "id": "17b1939924ae23b7",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T06:16:40.393981Z",
     "start_time": "2025-02-09T06:16:40.388961Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data = tokens[:train_index]\n",
    "test_data = tokens[train_index:]\n",
    "\n",
    "batch_size =4\n",
    "seq_len = 20\n",
    "vocab_szie = tokenizer.n_vocab\n"
   ],
   "id": "354c8fdee05657b0",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T11:31:18.406076Z",
     "start_time": "2025-02-09T11:31:18.401436Z"
    }
   },
   "cell_type": "code",
   "source": "- (0-7) * 2 ** (-(0 + 2))",
   "id": "d52858d560045bfb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.75"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "c6e31a65c1e0d1cd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "ba3d68677213d29a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-09T12:50:40.792181Z",
     "start_time": "2025-02-09T12:50:40.780440Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "# 假设 enc_outputs_scores 是一个 (3, 5) 的张量\n",
    "enc_outputs_scores = torch.tensor([[0.1, 0.4, 0.5, 0.3, 0.2],\n",
    "                                    [0.2, 0.3, 0.8, 0.6, 0.1],\n",
    "                                    [0.5, 0.2, 0.9, 0.3, 0.4]])\n",
    "\n",
    "num_queries = 2\n",
    "\n",
    "# 获取最大值和索引\n",
    "max_values, max_indices = enc_outputs_scores.max(dim=-1)  # max_values 是一维张量\n",
    "print(max_values,max_indices)\n",
    "# 如果你想获取每一行的前 num_queries 个最大值，可以直接在 enc_outputs_scores 上进行操作\n",
    "print(torch.topk(enc_outputs_scores, num_queries, dim=1))\n",
    "topk_ind = torch.topk(enc_outputs_scores, num_queries, dim=1).indices.view(-1)\n",
    "\n",
    "print(topk_ind)  # 输出结果"
   ],
   "id": "3b46456d9f931865",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5000, 0.8000, 0.9000]) tensor([2, 2, 2])\n",
      "torch.return_types.topk(\n",
      "values=tensor([[0.5000, 0.4000],\n",
      "        [0.8000, 0.6000],\n",
      "        [0.9000, 0.5000]]),\n",
      "indices=tensor([[2, 1],\n",
      "        [2, 3],\n",
      "        [2, 0]]))\n",
      "tensor([2, 1, 2, 3, 2, 0])\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
